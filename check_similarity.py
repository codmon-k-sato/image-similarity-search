#!/usr/bin/env python3
"""
2ã¤ã®ç”»åƒã®é¡ä¼¼åº¦ã‚’è¨ˆç®—ã™ã‚‹ã‚¹ã‚¯ãƒªãƒ—ãƒˆ
"""
import os
import sys
import numpy as np
from PIL import Image
import torch
import torchvision.transforms as T
import torchvision.models as models

class FeatureExtractor:
    def __init__(self):
        self.device = torch.device("cpu")
        self.backbone = models.resnet50(pretrained=True)
        self.backbone = torch.nn.Sequential(*(list(self.backbone.children())[:-1]))
        self.backbone = self.backbone.to(self.device)
        self.backbone.eval()

        self.transform = T.Compose([
            T.Resize((224, 224)),
            T.ToTensor(),
            T.Normalize(mean=[0.485, 0.456, 0.406],
                        std=[0.229, 0.224, 0.225])
        ])
        for p in self.backbone.parameters():
            p.requires_grad = False

    def extract(self, image_path):
        try:
            img = Image.open(image_path).convert("RGB")
            x = self.transform(img).unsqueeze(0).to(self.device)
            with torch.no_grad():
                feats = self.backbone(x)
            feats = feats.squeeze().cpu().numpy().astype('float32')
            norm = np.linalg.norm(feats)
            if norm > 0:
                feats = feats / norm
            img.close()
            return feats
        except Exception as e:
            print(f"Error processing {image_path}: {e}")
            return None

def cosine_similarity(vec1, vec2):
    """ã‚³ã‚µã‚¤ãƒ³é¡ä¼¼åº¦ã‚’è¨ˆç®—"""
    return np.dot(vec1, vec2)

if __name__ == "__main__":
    if len(sys.argv) != 3:
        print("ä½¿ç”¨æ–¹æ³•: python check_similarity.py <ç”»åƒ1ã®ãƒ‘ã‚¹> <ç”»åƒ2ã®ãƒ‘ã‚¹>")
        sys.exit(1)

    image1_path = sys.argv[1]
    image2_path = sys.argv[2]

    if not os.path.exists(image1_path):
        print(f"âŒ ç”»åƒ1ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“: {image1_path}")
        sys.exit(1)

    if not os.path.exists(image2_path):
        print(f"âŒ ç”»åƒ2ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“: {image2_path}")
        sys.exit(1)

    print("=" * 60)
    print("ğŸ” ç”»åƒé¡ä¼¼åº¦ãƒã‚§ãƒƒã‚¯")
    print("=" * 60)
    print(f"ç”»åƒ1: {image1_path}")
    print(f"ç”»åƒ2: {image2_path}")
    print("=" * 60)

    extractor = FeatureExtractor()

    print("ğŸ§  ç‰¹å¾´æŠ½å‡ºä¸­...")
    feat1 = extractor.extract(image1_path)
    feat2 = extractor.extract(image2_path)

    if feat1 is None or feat2 is None:
        print("âŒ ç‰¹å¾´æŠ½å‡ºã«å¤±æ•—ã—ã¾ã—ãŸ")
        sys.exit(1)

    similarity = cosine_similarity(feat1, feat2)

    print("=" * 60)
    print(f"ğŸ“Š ã‚³ã‚µã‚¤ãƒ³é¡ä¼¼åº¦: {similarity:.6f}")
    print("=" * 60)

    # åˆ¤å®šã‚’è¡¨ç¤º
    if similarity >= 0.90:
        print("âœ… éå¸¸ã«é¡ä¼¼ã—ã¦ã„ã‚‹ï¼ˆ0.90ä»¥ä¸Šï¼‰")
    elif similarity >= 0.80:
        print("ğŸŸ¡ é¡ä¼¼ã—ã¦ã„ã‚‹ï¼ˆ0.80-0.90ï¼‰")
    elif similarity >= 0.70:
        print("ğŸŸ  ã‚„ã‚„é¡ä¼¼ã—ã¦ã„ã‚‹ï¼ˆ0.70-0.80ï¼‰")
    else:
        print("âŒ é¡ä¼¼åº¦ãŒä½ã„ï¼ˆ0.70æœªæº€ï¼‰")
